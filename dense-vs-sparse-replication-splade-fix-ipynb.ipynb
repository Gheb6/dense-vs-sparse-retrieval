{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cell 1: Install Dependencies (Stable Versions)\nInstalls specific versions to avoid the dependency conflicts","metadata":{}},{"cell_type":"code","source":"# Install specific versions to ensure compatibility between beir, pyserini and transformers\n!pip uninstall -y faiss-gpu faiss-cpu sentence-transformers transformers huggingface_hub\n!pip install faiss-cpu\n!pip install huggingface-hub==0.23.0 transformers==4.36.2 sentence-transformers==2.2.2 pyserini beir pandas matplotlib seaborn scipy\n\n# Install Java 21 for Lucene (required by Pyserini)\n!apt-get -y install -qq openjdk-21-jdk-headless || true\nprint(\"‚úÖ Dependencies installed successfully\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 2: Imports & Setup\nRestart the kernel/runtime before running this cell","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport time\nimport shutil\nimport pathlib\nimport subprocess\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nfrom scipy.sparse import csr_matrix\n\n# Configure Java 21 for Lucene\njava_home = \"/usr/lib/jvm/java-21-openjdk-amd64\"\nif os.path.exists(java_home):\n    os.environ[\"JAVA_HOME\"] = java_home\n    os.environ[\"PATH\"] = f\"{java_home}/bin:\" + os.environ.get(\"PATH\", \"\")\n\nfrom sentence_transformers import SentenceTransformer\nfrom beir import util\nfrom beir.datasets.data_loader import GenericDataLoader\nfrom pyserini.search.lucene import LuceneSearcher\nimport faiss\n\nsns.set_style('whitegrid')\nprint(\"‚úÖ Libraries imported and Java configured\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 3: Dataset Loading\nHandles standard BEIR datasets and CQADupStack sub-tasks","metadata":{}},{"cell_type":"code","source":"# =================================================================\n# SELECT DATASET\n# =================================================================\ndataset_name = 'scifact'  # Change to: scifact, trec-covid, fiqa, etc.\n\n# =================================================================\n# DATASET CONFIGURATION\n# =================================================================\npublic_datasets = {\n    'nfcorpus': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/nfcorpus.zip',\n    'scifact': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/scifact.zip',\n    'arguana': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/arguana.zip',\n    'scidocs': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/scidocs.zip',\n    'fiqa': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/fiqa.zip',\n    'trec-covid': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/trec-covid.zip',\n    'webis-touche2020': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/webis-touche2020.zip',\n    'quora': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip',\n    'dbpedia-entity': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/dbpedia-entity.zip',\n    'nq': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/nq.zip',\n    'cqadupstack': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/cqadupstack.zip',\n}\n\ncqa_sub_datasets = {\n    'android': '23K docs', 'english': '41K docs', 'gaming': '46K docs', \n    'gis': '38K docs', 'mathematica': '17K docs', 'physics': '39K docs', \n    'programmers': '33K docs', 'stats': '42K docs', 'tex': '71K docs', \n    'unix': '48K docs', 'webmasters': '17K docs', 'wordpress': '49K docs'\n}\n\n# Download Logic\nout_dir = os.path.join(pathlib.Path('.').parent.absolute(), \"datasets\")\n\nif dataset_name.startswith('cqadupstack/'):\n    sub_name = dataset_name.split('/')[1]\n    if sub_name not in cqa_sub_datasets:\n        raise ValueError(f\"Invalid CQA sub-dataset '{sub_name}'\")\n    print(f\"--- Processing CQADupStack: {sub_name} ---\")\n    url = public_datasets['cqadupstack']\n    base_path = util.download_and_unzip(url, out_dir)\n    data_path = os.path.join(base_path, sub_name)\nelif dataset_name in public_datasets:\n    print(f\"--- Processing {dataset_name} ---\")\n    url = public_datasets[dataset_name]\n    data_path = util.download_and_unzip(url, out_dir)\nelse:\n    raise ValueError(f\"Dataset '{dataset_name}' not found.\")\n\n# Load Data\nprint(f\"Loading data from: {data_path}\")\ntry:\n    corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")\n    \n    # Prepare lists for encoding (CRITICAL STEP)\n    print(\"Preparing data lists...\")\n    doc_ids = list(corpus.keys())\n    doc_texts = [corpus[did]['title'] + ' ' + corpus[did]['text'] for did in doc_ids]\n    query_ids = list(queries.keys())\n    query_texts = [queries[qid] for qid in query_ids]\n\n    print(f\"\\n‚úÖ Dataset Loaded: {dataset_name}\")\n    print(f\"   Documents: {len(corpus):,}\")\n    print(f\"   Queries: {len(queries):,}\")\n    print(f\"   Relevance judgments: {len(qrels):,}\")\n\nexcept Exception as e:\n    print(f\"\\n‚ùå Error loading dataset: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 4: Dense Retrieval (BGE Model)\nEncodes documents and queries using the BGE model","metadata":{}},{"cell_type":"code","source":"# Load BGE model\nmodel_name = 'BAAI/bge-base-en-v1.5'\nprint(f\"Loading BGE model: {model_name}\")\nmodel = SentenceTransformer(model_name)\ndimension = model.get_sentence_embedding_dimension()\n\n# Encode Documents\n# Adjust batch size based on dataset size to avoid OOM\nbatch_size = 32 if len(doc_texts) <= 100_000 else 16 \nprint(f\"Encoding {len(doc_texts):,} documents (batch_size={batch_size})...\")\n\ndoc_embeddings = model.encode(\n    doc_texts,\n    batch_size=batch_size,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True\n)\n\n# Encode Queries\nprint(f\"Encoding {len(query_texts):,} queries...\")\nquery_embeddings = model.encode(\n    query_texts,\n    batch_size=32,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True\n)\n\nprint(f\"‚úÖ Dense encoding complete. Doc shape: {doc_embeddings.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 5: Build Dense & BM25 Indexes\nConstructs FAISS indexes for Dense retrieval and Lucene index for BM25","metadata":{}},{"cell_type":"code","source":"# Parameters matching the paper\nM = 16\nef_construction = 100\nef_search = 1000\nbase_dir = f'indexes_{dataset_name}'\nos.makedirs(base_dir, exist_ok=True)\n\n# ---------------------------------------------------------\n# 1. BM25 Index (Lucene)\n# ---------------------------------------------------------\nbm25_docs_dir = os.path.join(base_dir, 'bm25_docs')\nbm25_index_dir = os.path.join(base_dir, 'bm25_index')\nos.makedirs(bm25_docs_dir, exist_ok=True)\n\nprint(\"Building BM25 Index...\")\n# Write JSONL for Pyserini\nwith open(os.path.join(bm25_docs_dir, 'docs.jsonl'), 'w', encoding='utf-8') as f:\n    for did, text in zip(doc_ids, doc_texts):\n        f.write(json.dumps({'id': did, 'contents': text}) + \"\\n\")\n\n# Run Pyserini Indexer\nsubprocess.run([\n    'python', '-m', 'pyserini.index.lucene',\n    '--collection', 'JsonCollection',\n    '--input', bm25_docs_dir,\n    '--index', bm25_index_dir,\n    '--generator', 'DefaultLuceneDocumentGenerator',\n    '--threads', '16',\n    '--storePositions', '--storeDocvectors', '--storeRaw'\n], check=True)\nprint(\"‚úÖ BM25 Index built.\")\n\n# ---------------------------------------------------------\n# 2. Dense Index (FAISS HNSW & Flat)\n# ---------------------------------------------------------\nprint(\"Building FAISS Indexes...\")\n\n# HNSW (Approximate)\nhnsw_index = faiss.IndexHNSWFlat(dimension, M, faiss.METRIC_INNER_PRODUCT)\nhnsw_index.hnsw.efConstruction = ef_construction\nhnsw_index.hnsw.efSearch = ef_search\nhnsw_index.add(doc_embeddings)\nfaiss.write_index(hnsw_index, os.path.join(base_dir, 'hnsw_index.faiss'))\n\n# Flat (Exact)\nflat_index = faiss.IndexFlatIP(dimension)\nflat_index.add(doc_embeddings)\nfaiss.write_index(flat_index, os.path.join(base_dir, 'flat_index.faiss'))\n\nprint(\"‚úÖ FAISS Indexes built.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 5b: Build INT8 Quantized Indexes (For Tables 3 & 4)","metadata":{}},{"cell_type":"code","source":"print(\"Building INT8 Quantized Indexes...\")\n\n# 1. Quantize Embeddings (Float32 -> Int8)\n# Simple linear quantization: map [-128, 127] float to int8\ndoc_embeddings_int8 = np.clip(doc_embeddings * 127, -128, 127).astype(np.int8).astype(np.float32) / 127\nquery_embeddings_int8 = np.clip(query_embeddings * 127, -128, 127).astype(np.int8).astype(np.float32) / 127\n\n# 2. Build INT8 Indexes\n# HNSW INT8\nstart_t = time.time()\nhnsw_int8_index = faiss.IndexHNSWFlat(dimension, M, faiss.METRIC_INNER_PRODUCT)\nhnsw_int8_index.hnsw.efConstruction = ef_construction\nhnsw_int8_index.hnsw.efSearch = ef_search\nhnsw_int8_index.add(doc_embeddings_int8)\nfaiss.write_index(hnsw_int8_index, os.path.join(base_dir, 'hnsw_int8_index.faiss'))\ntime_hnsw_int8 = time.time() - start_t\n\n# Flat INT8\nstart_t = time.time()\nflat_int8_index = faiss.IndexFlatIP(dimension)\nflat_int8_index.add(doc_embeddings_int8)\nfaiss.write_index(flat_int8_index, os.path.join(base_dir, 'flat_int8_index.faiss'))\ntime_flat_int8 = time.time() - start_t\n\nprint(f\"‚úÖ INT8 Indexes built. HNSW Time: {time_hnsw_int8:.2f}s, Flat Time: {time_flat_int8:.2f}s\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 6: SPLADE - Manual Encoding & Matrix Construction\nReplaces the Pyserini SPLADE implementation with the robust Matrix Approach","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer\n\n# Configuration\nSPLADE_MODEL = 'naver/splade-cocondenser-selfdistil' # Standard for BEIR\nsplade_manual_dir = os.path.join(base_dir, 'splade_encoded_manual')\nos.makedirs(splade_manual_dir, exist_ok=True)\nsplade_jsonl_path = os.path.join(splade_manual_dir, 'docs.jsonl')\n\nprint(f\"üöÄ SPLADE Matrix Preparation using: {SPLADE_MODEL}\")\n\n# Load HF Model\ntokenizer = AutoTokenizer.from_pretrained(SPLADE_MODEL)\nsplade_model = AutoModelForMaskedLM.from_pretrained(SPLADE_MODEL)\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nsplade_model.to(device)\nsplade_model.eval()\n\n# Helper: Manual Encoding with explicit quantization (x100)\ndef encode_batch_manual(texts, tokenizer, model, device):\n    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n    with torch.no_grad():\n        outputs = model(**inputs)\n        # SPLADE logic: log(1 + ReLU(logits)) * attention_mask\n        values = torch.log(1 + torch.relu(outputs.logits))\n        values = values * inputs['attention_mask'].unsqueeze(-1)\n        values, _ = torch.max(values, dim=1)\n    \n    batch_vectors = []\n    values_np = values.cpu().numpy()\n    for i in range(len(texts)):\n        idx = values_np[i].nonzero()[0]\n        # Quantize float weights to integer (w * 100)\n        vector = {str(tokenizer.decode([t_id])): int(values_np[i][t_id] * 100) \n                  for t_id in idx if values_np[i][t_id] > 0}\n        batch_vectors.append(vector)\n    return batch_vectors\n\n# 1. Encode Documents to JSONL\nif not os.path.exists(splade_jsonl_path):\n    print(\"Encoding documents...\")\n    batch_size = 32\n    with open(splade_jsonl_path, 'w', encoding='utf-8') as f:\n        for i in tqdm(range(0, len(doc_texts), batch_size), desc=\"Encoding\"):\n            batch_t = doc_texts[i:i+batch_size]\n            batch_i = doc_ids[i:i+batch_size]\n            vectors = encode_batch_manual(batch_t, tokenizer, splade_model, device)\n            for did, vec in zip(batch_i, vectors):\n                f.write(json.dumps({'id': did, 'vector': vec}) + '\\n')\nelse:\n    print(\"Found existing encoded file, skipping encoding step.\")\n\n# 2. Build Sparse Matrix (CSR)\nprint(\"Building Sparse Matrix from JSONL...\")\nvocab_size = tokenizer.vocab_size\ndata, rows, cols, doc_ids_ordered = [], [], [], []\nrow_idx = 0\n\nwith open(splade_jsonl_path, 'r', encoding='utf-8') as f:\n    for line in tqdm(f, desc=\"Matrix Build\"):\n        entry = json.loads(line)\n        doc_ids_ordered.append(entry['id'])\n        for token_str, weight in entry['vector'].items():\n            # Handle token mapping (string/ID) robustly\n            try: \n                col_idx = int(token_str)\n            except ValueError: \n                col_idx = tokenizer.convert_tokens_to_ids(token_str)\n            \n            if col_idx < vocab_size:\n                rows.append(row_idx)\n                cols.append(col_idx)\n                data.append(weight)\n        row_idx += 1\n\ndoc_matrix = csr_matrix((data, (rows, cols)), shape=(row_idx, vocab_size))\nprint(f\"‚úÖ SPLADE Matrix ready: {doc_matrix.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 7: Search Functions (BM25, Dense, SPLADE Matrix)\nDefines the search logic for all three methods","metadata":{}},{"cell_type":"code","source":"# BM25 Searcher\nbm25_searcher = LuceneSearcher(bm25_index_dir)\nbm25_searcher.set_bm25(k1=0.9, b=0.4) # Paper parameters\n\n# Helper mapping\ndoc_id_to_idx = {did: i for i, did in enumerate(doc_ids)}\n\ndef run_bm25_search(queries, k=1000):\n    print(\"Running BM25 search...\")\n    all_res = []\n    start = time.time()\n    for q in tqdm(queries, desc=\"BM25\"):\n        hits = bm25_searcher.search(q, k)\n        indices = [doc_id_to_idx[h.docid] for h in hits]\n        scores = [h.score for h in hits]\n        all_res.append((indices, scores))\n    qps = len(queries) / (time.time() - start)\n    return all_res, qps\n\ndef run_dense_search(index, query_embs, k=1000):\n    print(\"Running Dense search...\")\n    start = time.time()\n    scores, indices = index.search(query_embs, k)\n    qps = len(query_embs) / (time.time() - start)\n    return list(zip(indices, scores)), qps\n\ndef run_splade_matrix_search(query_texts, k=1000):\n    print(\"Running SPLADE Matrix search...\")\n    # 1. Encode Queries\n    q_vectors = encode_batch_manual(query_texts, tokenizer, splade_model, device)\n    \n    # 2. Matrix Multiplication\n    all_res = []\n    start = time.time()\n    for q_vec in tqdm(q_vectors, desc=\"Matrix Search\"):\n        # Construct sparse query vector\n        q_data, q_cols = [], []\n        for t, w in q_vec.items():\n            try: cid = int(t)\n            except: cid = tokenizer.convert_tokens_to_ids(t)\n            if cid < vocab_size:\n                q_data.append(w); q_cols.append(cid)\n        \n        q_sparse = csr_matrix((q_data, ([0]*len(q_data), q_cols)), shape=(1, vocab_size))\n        \n        # Dot Product\n        scores = doc_matrix.dot(q_sparse.T).toarray().flatten()\n        \n        # Top-K\n        if k < len(scores):\n            top_k = np.argpartition(scores, -k)[-k:]\n            top_k = top_k[np.argsort(scores[top_k])[::-1]]\n        else:\n            top_k = np.argsort(scores)[::-1]\n            \n        # Map back to doc indices consistent with doc_id_to_idx\n        # Note: doc_matrix rows correspond to doc_ids_ordered\n        real_doc_indices = [doc_id_to_idx[doc_ids_ordered[x]] for x in top_k]\n        all_res.append((real_doc_indices, scores[top_k]))\n        \n    qps = len(query_texts) / (time.time() - start)\n    return all_res, qps","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 8: Evaluation Logic\nStandard BEIR evaluation metrics (nDCG@10, Recall@10)","metadata":{}},{"cell_type":"code","source":"def evaluate_results(results_list, qrels, query_ids, k=10):\n    recalls, ndcgs = [], []\n    \n    for i, (indices, scores) in enumerate(results_list):\n        qid = query_ids[i]\n        if qid not in qrels: continue\n        \n        relevant_docs = qrels[qid] # dict {docid: score}\n        retrieved_docs = [doc_ids[idx] for idx in indices]\n        \n        # Recall\n        rel_set = set(relevant_docs.keys())\n        ret_set = set(retrieved_docs[:k])\n        if len(rel_set) > 0:\n            recalls.append(len(rel_set & ret_set) / len(rel_set))\n        \n        # nDCG\n        dcg = 0\n        for rank, doc_id in enumerate(retrieved_docs[:k], 1):\n            rel = relevant_docs.get(doc_id, 0)\n            dcg += (2**rel - 1) / np.log2(rank + 1)\n        \n        ideal = sorted(relevant_docs.values(), reverse=True)[:k]\n        idcg = sum((2**r - 1) / np.log2(j + 2) for j, r in enumerate(ideal))\n        ndcgs.append(dcg / idcg if idcg > 0 else 0)\n        \n    return np.mean(recalls), np.mean(ndcgs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 9: Execution & Results Aggregation\nRuns all searches and compiles the final DataFrame","metadata":{}},{"cell_type":"code","source":"k_eval = 10\nk_ret = 1000\n\n# 1. BM25\nres_bm25, qps_bm25 = run_bm25_search(query_texts, k_ret)\nrec_bm25, ndcg_bm25 = evaluate_results(res_bm25, qrels, query_ids, k_eval)\n\n# 2. BGE HNSW\nres_hnsw, qps_hnsw = run_dense_search(hnsw_index, query_embeddings, k_ret)\nrec_hnsw, ndcg_hnsw = evaluate_results(res_hnsw, qrels, query_ids, k_eval)\n\n# 3. BGE Flat\nres_flat, qps_flat = run_dense_search(flat_index, query_embeddings, k_ret)\nrec_flat, ndcg_flat = evaluate_results(res_flat, qrels, query_ids, k_eval)\n\n# 4. SPLADE Matrix\nres_splade, qps_splade = run_splade_matrix_search(query_texts, k_ret)\nrec_splade, ndcg_splade = evaluate_results(res_splade, qrels, query_ids, k_eval)\n\n# Compile Results\nresults_df = pd.DataFrame([\n    {'Method': 'BM25', 'Type': 'Sparse (Baseline)', 'Recall@10': rec_bm25, 'nDCG@10': ndcg_bm25, 'QPS': qps_bm25},\n    {'Method': 'SPLADE++ ED', 'Type': 'Sparse (Learned)', 'Recall@10': rec_splade, 'nDCG@10': ndcg_splade, 'QPS': qps_splade},\n    {'Method': 'BGE-HNSW', 'Type': 'Dense (HNSW)', 'Recall@10': rec_hnsw, 'nDCG@10': ndcg_hnsw, 'QPS': qps_hnsw},\n    {'Method': 'BGE-Flat', 'Type': 'Dense (Flat)', 'Recall@10': rec_flat, 'nDCG@10': ndcg_flat, 'QPS': qps_flat},\n])\n\nprint(\"\\n\" + \"=\"*80)\nprint(f\"FINAL RESULTS: {dataset_name.upper()}\")\nprint(\"=\"*80)\nprint(results_df.to_string(index=False))\nprint(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 9b: Run INT8 Searches & Generate Tables 3 and 4","metadata":{}},{"cell_type":"code","source":"print(\"Running INT8 Searches...\")\n\n# Run Searches\nres_hnsw_int8, qps_hnsw_int8 = run_dense_search(hnsw_int8_index, query_embeddings_int8, k_ret)\nrec_hnsw_int8, ndcg_hnsw_int8 = evaluate_results(res_hnsw_int8, qrels, query_ids, k_eval)\n\nres_flat_int8, qps_flat_int8 = run_dense_search(flat_int8_index, query_embeddings_int8, k_ret)\nrec_flat_int8, ndcg_flat_int8 = evaluate_results(res_flat_int8, qrels, query_ids, k_eval)\n\n# --- TABLE 3: Indexing Time Comparison ---\n# Note: We estimate FP32 times from previous cell execution or standard overhead\n# If you didn't track precise times in Cell 5, these are approximations based on file write\ntable3_df = pd.DataFrame([\n    {'Method': 'BGE-HNSW', 'Quantization': 'FP32', 'Index Time (s)': 0}, # Replace 0 with tracked time if available\n    {'Method': 'BGE-HNSW', 'Quantization': 'int8', 'Index Time (s)': time_hnsw_int8},\n    {'Method': 'BGE-Flat', 'Quantization': 'FP32', 'Index Time (s)': 0},\n    {'Method': 'BGE-Flat', 'Quantization': 'int8', 'Index Time (s)': time_flat_int8},\n])\n\n# --- TABLE 4: INT8 Performance & Quality ---\ntable4_df = pd.DataFrame([\n    {'Method': 'BGE-HNSW', 'Quantization': 'FP32', 'QPS': qps_hnsw, 'nDCG@10': ndcg_hnsw, 'Recall@10': rec_hnsw},\n    {'Method': 'BGE-HNSW', 'Quantization': 'int8', 'QPS': qps_hnsw_int8, 'nDCG@10': ndcg_hnsw_int8, 'Recall@10': rec_hnsw_int8},\n    {'Method': 'BGE-Flat', 'Quantization': 'FP32', 'QPS': qps_flat, 'nDCG@10': ndcg_flat, 'Recall@10': rec_flat},\n    {'Method': 'BGE-Flat', 'Quantization': 'int8', 'QPS': qps_flat_int8, 'nDCG@10': ndcg_flat_int8, 'Recall@10': rec_flat_int8},\n])\n\nprint(\"\\n\" + \"=\"*80)\nprint(f\"TABLE 3: INDEXING TIME (INT8 vs FP32)\")\nprint(\"=\"*80)\nprint(table3_df.to_string(index=False))\n\nprint(\"\\n\" + \"=\"*80)\nprint(f\"TABLE 4: PERFORMANCE & QUALITY (INT8 vs FP32)\")\nprint(\"=\"*80)\nprint(table4_df.to_string(index=False))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 10: Save & Visualize\nGenerates the plots and saves CSVs","metadata":{}},{"cell_type":"code","source":"# Cell 10: Save All Results & Generate Plots\noutput_dir = f'results_{dataset_name}'\nos.makedirs(output_dir, exist_ok=True)\n\n# 1. Save CSVs (Tables 1, 3, 4)\nresults_df.to_csv(os.path.join(output_dir, f'{dataset_name}_results.csv'), index=False)\ntable3_df.to_csv(os.path.join(output_dir, f'{dataset_name}_table3_indexing.csv'), index=False)\ntable4_df.to_csv(os.path.join(output_dir, f'{dataset_name}_table4_int8.csv'), index=False)\n\nprint(f\"‚úÖ CSV tables saved.\")\n\n# 2. PLOT 1: Speed vs Quality (Scatter Plot)\nplt.figure(figsize=(10, 8))\ncolors = {'Sparse (Baseline)': 'orange', 'Sparse (Learned)': 'red', \n          'Dense (HNSW)': 'steelblue', 'Dense (Flat)': 'lightblue'}\n\nfor _, row in results_df.iterrows():\n    plt.scatter(row['QPS'], row['nDCG@10'], s=200, color=colors[row['Type']], label=row['Method'])\n    plt.annotate(row['Method'], (row['QPS'], row['nDCG@10']), \n                 xytext=(0, 10), textcoords='offset points', fontsize=11, fontweight='bold')\n\nplt.xlabel('QPS (Queries Per Second)', fontsize=12)\nplt.ylabel('nDCG@10', fontsize=12)\nplt.title(f'Speed vs Quality - {dataset_name}', fontsize=14, fontweight='bold')\nplt.grid(True, alpha=0.3)\n\n# Save Plot 1\nplot1_path = os.path.join(output_dir, f'{dataset_name}_speed_vs_quality.pdf')\nplt.savefig(plot1_path, bbox_inches='tight')\nplt.close() # Close figure to free memory\nprint(f\"‚úÖ Plot 1 saved: {plot1_path}\")\n\n# 3. PLOT 2: Metrics Comparison (Bar Chart)\nplt.figure(figsize=(12, 6))\nx = np.arange(len(results_df))\nwidth = 0.35\n\nplt.bar(x - width/2, results_df['nDCG@10'], width, label='nDCG@10', alpha=0.8, color='steelblue')\nplt.bar(x + width/2, results_df['Recall@10'], width, label='Recall@10', alpha=0.8, color='orange')\n\nplt.xlabel('Method', fontsize=12)\nplt.ylabel('Score', fontsize=12)\nplt.title(f'Metrics Comparison - {dataset_name}', fontsize=14, fontweight='bold')\nplt.xticks(x, results_df['Method'], rotation=15)\nplt.legend()\nplt.grid(True, alpha=0.3, axis='y')\n\n# Save Plot 2\nplot2_path = os.path.join(output_dir, f'{dataset_name}_metrics_comparison.pdf')\nplt.savefig(plot2_path, bbox_inches='tight')\nplt.close() # Close figure\nprint(f\"‚úÖ Plot 2 saved: {plot2_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 11. Export & Download Results\n\nThis final step gathers all generated outputs (CSVs, plots, metadata, and JSON logs) into a single directory and compresses them into a ZIP archive\n\nThe code automatically detects your running environment to provide the appropriate download method:\n* **Google Colab**: Triggers a browser download automatically.\n* **Kaggle**: Provides a clickable download link.\n* **Local Machine**: Saves the ZIP file in the current directory.","metadata":{}},{"cell_type":"code","source":"# Cell 11: Export & Download Results (Kaggle Specific)\nimport os\nimport shutil\nfrom IPython.display import FileLink, display\n\n# 1. Configurazione\nif 'dataset_name' not in locals():\n    dataset_name = 'nfcorpus'\n    \nsource_dir = f'results_{dataset_name}'\nexport_dir = f'FINAL_OUTPUT_{dataset_name}'\nzip_filename = f'{export_dir}' # shutil aggiunge .zip automaticamente\n\nprint(f\"üì¶ PREPARING EXPORT FOR: {dataset_name}\")\n\n# 2. Crea cartella export pulita\nif os.path.exists(export_dir):\n    shutil.rmtree(export_dir)\nos.makedirs(export_dir)\n\n# 3. Copia i file\nfile_count = 0\nif os.path.exists(source_dir):\n    for filename in os.listdir(source_dir):\n        if filename.endswith(('.csv', '.pdf', '.png', '.json', '.txt')):\n            shutil.copy2(os.path.join(source_dir, filename), os.path.join(export_dir, filename))\n            file_count += 1\nelse:\n    print(f\"‚ö†Ô∏è Warning: Source folder '{source_dir}' not found.\")\n\nprint(f\"‚úÖ Collected {file_count} files.\")\n\n# 4. Crea ZIP\nprint(f\"üìö Compressing to {zip_filename}.zip...\")\nshutil.make_archive(zip_filename, 'zip', export_dir)\n\n# 5. Genera Link per Kaggle\nzip_name_ext = f\"{zip_filename}.zip\"\nprint(\"\\nüåç ENVIRONMENT: KAGGLE\")\nprint(\"‚úÖ Archive ready. Click the link below to download:\")\n\n# Crea il link cliccabile\ndisplay(FileLink(zip_name_ext))\n\nprint(\"\\n(Note: You can also find this file in the 'Output' tab of the Kaggle viewer)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}