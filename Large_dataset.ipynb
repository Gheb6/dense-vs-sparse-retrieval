{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064d3fcb",
   "metadata": {},
   "source": [
    "## Debug: Check Available Indexing Options\n",
    "\n",
    "Let's check what indexing options are available in pyserini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6295e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check available indexing options\n",
    "# import subprocess\n",
    "# result = subprocess.run(\n",
    "#     ['python', '-m', 'pyserini.index.lucene', '-options'],\n",
    "#     capture_output=True,\n",
    "#     text=True\n",
    "# )\n",
    "# print(\"STDOUT:\")\n",
    "# print(result.stdout)\n",
    "# print(\"\\nSTDERR:\")\n",
    "# print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ad26b0",
   "metadata": {},
   "source": [
    "# Paper Replication: Dense vs Sparse Retrieval on BEIR\n",
    "\n",
    "This notebook replicates results from **Table 1** of the paper comparing:\n",
    "- **Dense**: BGE (bge-base-en-v1.5) with HNSW and Flat indexes\n",
    "- **Sparse**: SPLADE++ EnsembleDistil and BM25 baseline\n",
    "- **Metrics**: Recall@10, nDCG@10, QPS (queries per second)\n",
    "\n",
    "## Key Implementation Details\n",
    "\n",
    "**Exact Paper Parameters:**\n",
    "- Library: Lucene 9.9.1 via Pyserini/Anserini\n",
    "- HNSW: M=16, efConstruction=100, efSearch=1000\n",
    "- Threads: 16 (indexing and search)\n",
    "- Retrieval: k=1000 hits\n",
    "- Evaluation: Recall@10, nDCG@10\n",
    "- QPS: Measured with 16 threads\n",
    "\n",
    "**Datasets:** The paper evaluates 29 BEIR datasets. Change `dataset_name` below to run on different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a7e6c",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Install Pyserini (Anserini Python bindings), sentence-transformers (for BGE), BEIR, and FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers pyserini beir faiss-cpu pandas matplotlib seaborn\n",
    "# Install Java 21 for Lucene (class version 65)\n",
    "!apt-get -y install -qq openjdk-21-jdk-headless || true\n",
    "print(\"✅ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e5dbc",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports\n",
    "\n",
    "⚠️ **IMPORTANT**: After installing dependencies, restart the runtime/kernel before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d34b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import subprocess\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configure Java 21 for Lucene\n",
    "java_home = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
    "if os.path.exists(java_home):\n",
    "    os.environ[\"JAVA_HOME\"] = java_home\n",
    "    os.environ[\"PATH\"] = f\"{java_home}/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from beir import util\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "print(\"✅ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2fa2db",
   "metadata": {},
   "source": [
    "## 3. Dataset Selection\n",
    "\n",
    "Select a BEIR dataset. The paper evaluates 29 datasets - here we can run on any individual dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497300ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select dataset from BEIR\n",
    "dataset_name = 'scifact'  # Change to: fiqa, trec-covid, nfcorpus, etc.\n",
    "\n",
    "# BEIR dataset URLs sorted by corpus cardinality (smallest to largest)\n",
    "dataset_urls = {\n",
    "    'nfcorpus': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/nfcorpus.zip',  # 3.6K docs\n",
    "    'scifact': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/scifact.zip',  # 5K docs\n",
    "    'arguana': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/arguana.zip',  # 8.7K docs\n",
    "    'scidocs': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/scidocs.zip',  # 25K docs\n",
    "    'fiqa': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/fiqa.zip',  # 57K docs\n",
    "    'trec-covid': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/trec-covid.zip',  # 171K docs\n",
    "    'webis-touche2020': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/webis-touche2020.zip',  # 382K docs\n",
    "    'quora': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip',  # 523K docs\n",
    "    'robust04': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/robust04.zip',  # 528K docs\n",
    "    'trec-news': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/trec-news.zip',  # 595K docs\n",
    "    'nq': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/nq.zip',  # 2.7M docs\n",
    "    'dbpedia-entity': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/dbpedia-entity.zip',  # 4.6M docs\n",
    "    'fever': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/fever.zip',  # 5.4M docs\n",
    "    'climate-fever': 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/climate-fever.zip',  # 5.4M docs\n",
    "}\n",
    "\n",
    "print(f\"Downloading {dataset_name} dataset...\")\n",
    "url = dataset_urls[dataset_name]\n",
    "data_path = util.download_and_unzip(url, \"datasets\")\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")\n",
    "\n",
    "doc_ids = list(corpus.keys())\n",
    "doc_texts = [corpus[did]['title'] + ' ' + corpus[did]['text'] for did in doc_ids]\n",
    "query_ids = list(queries.keys())\n",
    "query_texts = [queries[qid] for qid in query_ids]\n",
    "\n",
    "print(f\"\\n✅ Dataset: {dataset_name}\")\n",
    "print(f\"   Documents: {len(corpus):,}\")\n",
    "print(f\"   Queries: {len(queries):,}\")\n",
    "print(f\"   Relevance judgments: {len(qrels):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daef149",
   "metadata": {},
   "source": [
    "## 4. Dense Retrieval: BGE Model\n",
    "\n",
    "Load BGE (bge-base-en-v1.5) and encode documents and queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41371ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BGE model (bge-base-en-v1.5)\n",
    "model_name = 'BAAI/bge-base-en-v1.5'\n",
    "print(f\"Loading BGE model: {model_name}\")\n",
    "model = SentenceTransformer(model_name)\n",
    "dimension = model.get_sentence_embedding_dimension()\n",
    "print(f\"✅ Model loaded (dimension={dimension})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9cdf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode documents\n",
    "batch_size = 32 if len(doc_texts) <= 100_000 else 16\n",
    "print(f\"Encoding {len(doc_texts):,} documents (batch_size={batch_size})...\")\n",
    "\n",
    "doc_embeddings = model.encode(\n",
    "    doc_texts,\n",
    "    batch_size=batch_size,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "print(f\"✅ Documents encoded: {doc_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce806da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode queries\n",
    "print(f\"Encoding {len(query_texts):,} queries...\")\n",
    "query_embeddings = model.encode(\n",
    "    query_texts,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "print(f\"✅ Queries encoded: {query_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83c88d",
   "metadata": {},
   "source": [
    "## 5. Build Lucene Indexes\n",
    "\n",
    "Build indexes for all retrieval methods:\n",
    "1. **BM25**: Inverted index\n",
    "2. **SPLADE++ ED**: Impact-based inverted index\n",
    "3. **BGE HNSW**: HNSW vector index (M=16, efC=100, efSearch=1000)\n",
    "4. **BGE Flat**: Flat vector index (brute-force search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper parameters\n",
    "M = 16  # HNSW M parameter\n",
    "ef_construction = 100  # HNSW efC\n",
    "ef_search = 1000  # HNSW efSearch\n",
    "threads = '16'  # 16 threads as per paper\n",
    "k_retrieve = 1000  # Retrieve 1000 hits\n",
    "k_eval = 10  # Evaluate at nDCG@10\n",
    "\n",
    "# Initialize index timing dictionary\n",
    "index_times = {}\n",
    "\n",
    "print(f\"Retrieval: k={k_retrieve}, evaluation@{k_eval}\")\n",
    "print(f\"Parameters: M={M}, efC={ef_construction}, efSearch={ef_search}, threads={threads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare directory structure\n",
    "base_dir = f'indexes_{dataset_name}'\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# 1. BM25 Index\n",
    "bm25_docs_dir = os.path.join(base_dir, 'bm25_docs')\n",
    "bm25_index_dir = os.path.join(base_dir, 'bm25_index')\n",
    "os.makedirs(bm25_docs_dir, exist_ok=True)\n",
    "\n",
    "print(\"Writing BM25 documents...\")\n",
    "bm25_jsonl = os.path.join(bm25_docs_dir, 'docs.jsonl')\n",
    "with open(bm25_jsonl, 'w', encoding='utf-8') as f:\n",
    "    for did, text in zip(doc_ids, doc_texts):\n",
    "        f.write(json.dumps({'id': did, 'contents': text}) + \"\\n\")\n",
    "\n",
    "print(\"Building BM25 index...\")\n",
    "bm25_start = time.time()\n",
    "subprocess.run([\n",
    "    'python', '-m', 'pyserini.index.lucene',\n",
    "    '--collection', 'JsonCollection',\n",
    "    '--input', bm25_docs_dir,\n",
    "    '--index', bm25_index_dir,\n",
    "    '--generator', 'DefaultLuceneDocumentGenerator',\n",
    "    '--threads', threads,\n",
    "    '--storePositions',\n",
    "    '--storeDocvectors',\n",
    "    '--storeRaw'\n",
    "], check=True)\n",
    "\n",
    "bm25_elapsed = time.time() - bm25_start\n",
    "print(f\"✅ BM25 index ready ({bm25_elapsed:.2f}s)\")\n",
    "index_times['BM25'] = bm25_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SPLADE++ ED Index\n",
    "splade_docs_dir = os.path.join(base_dir, 'splade_docs')\n",
    "splade_encoded_dir = os.path.join(base_dir, 'splade_encoded')\n",
    "splade_index_dir = os.path.join(base_dir, 'splade_index')\n",
    "os.makedirs(splade_docs_dir, exist_ok=True)\n",
    "os.makedirs(splade_encoded_dir, exist_ok=True)\n",
    "\n",
    "print(\"Writing SPLADE documents...\")\n",
    "splade_jsonl = os.path.join(splade_docs_dir, 'docs.jsonl')\n",
    "with open(splade_jsonl, 'w', encoding='utf-8') as f:\n",
    "    for did, text in zip(doc_ids, doc_texts):\n",
    "        f.write(json.dumps({'id': did, 'text': text}) + \"\\n\")\n",
    "\n",
    "print(\"Encoding with SPLADE++ EnsembleDistil (using GPU)...\")\n",
    "subprocess.run([\n",
    "    'python', '-m', 'pyserini.encode',\n",
    "    'input', '--corpus', splade_docs_dir,\n",
    "    '--fields', 'text',\n",
    "    'output', '--embeddings', splade_encoded_dir,\n",
    "    'encoder', '--encoder', 'naver/splade-cocondenser-ensembledistil',\n",
    "    '--device', 'cuda',\n",
    "    '--batch', '32'\n",
    "], check=True)\n",
    "\n",
    "print(\"Building SPLADE impact index...\")\n",
    "splade_start = time.time()\n",
    "subprocess.run([\n",
    "    'python', '-m', 'pyserini.index.lucene',\n",
    "    '--collection', 'JsonVectorCollection',\n",
    "    '--input', splade_encoded_dir,\n",
    "    '--index', splade_index_dir,\n",
    "    '--generator', 'DefaultLuceneDocumentGenerator',\n",
    "    '--impact',\n",
    "    '--threads', threads,\n",
    "    '--storeRaw'\n",
    "], check=True)\n",
    "\n",
    "splade_elapsed = time.time() - splade_start\n",
    "print(f\"✅ SPLADE++ ED index ready ({splade_elapsed:.2f}s)\")\n",
    "index_times['SPLADE++ ED'] = splade_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e880228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. BGE HNSW Index (using FAISS)\n",
    "import faiss\n",
    "\n",
    "hnsw_index_path = os.path.join(base_dir, 'hnsw_index.faiss')\n",
    "\n",
    "print(f\"Building FAISS HNSW index (M={M}, efC={ef_construction}, efSearch={ef_search})...\")\n",
    "hnsw_start = time.time()\n",
    "\n",
    "# Create HNSW index\n",
    "quantizer = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity (normalized vectors)\n",
    "hnsw_index = faiss.IndexHNSWFlat(dimension, M, faiss.METRIC_INNER_PRODUCT)\n",
    "hnsw_index.hnsw.efConstruction = ef_construction\n",
    "hnsw_index.hnsw.efSearch = ef_search\n",
    "\n",
    "# Add vectors to index\n",
    "print(f\"Adding {len(doc_embeddings):,} vectors to HNSW index...\")\n",
    "hnsw_index.add(doc_embeddings)\n",
    "\n",
    "# Save index\n",
    "faiss.write_index(hnsw_index, hnsw_index_path)\n",
    "hnsw_elapsed = time.time() - hnsw_start\n",
    "\n",
    "index_times['BGE-HNSW'] = hnsw_elapsed\n",
    "print(f\"✅ HNSW index saved ({hnsw_index.ntotal:,} vectors) ({hnsw_elapsed:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd34c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. BGE Flat Index (using FAISS, brute-force search)\n",
    "flat_index_path = os.path.join(base_dir, 'flat_index.faiss')\n",
    "\n",
    "print(\"Building FAISS Flat index (brute-force)...\")\n",
    "flat_start = time.time()\n",
    "\n",
    "# Create flat index for exact search\n",
    "flat_index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n",
    "flat_index.add(doc_embeddings)\n",
    "\n",
    "# Save index\n",
    "faiss.write_index(flat_index, flat_index_path)\n",
    "flat_elapsed = time.time() - flat_start\n",
    "\n",
    "index_times['BGE-Flat'] = flat_elapsed\n",
    "print(f\"✅ Flat index saved ({flat_index.ntotal:,} vectors) ({flat_elapsed:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a7e730",
   "metadata": {},
   "source": [
    "## 5a. Build INT8 Quantized Indexes\n",
    "\n",
    "Build int8 quantized versions for comparison with full precision indexes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INT8 Quantization: HNSW with int8 quantization\n",
    "hnsw_int8_index_path = os.path.join(base_dir, 'hnsw_int8_index.faiss')\n",
    "\n",
    "print(f\"Building INT8 HNSW index (M={M}, efC={ef_construction}, efSearch={ef_search})...\")\n",
    "hnsw_int8_start = time.time()\n",
    "\n",
    "# Convert float32 embeddings to int8 using simple quantization\n",
    "# Range: [-128, 127]\n",
    "doc_embeddings_int8 = np.clip(doc_embeddings * 127, -128, 127).astype(np.int8).astype(np.float32) / 127\n",
    "\n",
    "# Create HNSW index with int8 quantization\n",
    "quantizer_int8 = faiss.IndexFlatIP(dimension)\n",
    "hnsw_int8_index = faiss.IndexHNSWFlat(dimension, M, faiss.METRIC_INNER_PRODUCT)\n",
    "hnsw_int8_index.hnsw.efConstruction = ef_construction\n",
    "hnsw_int8_index.hnsw.efSearch = ef_search\n",
    "\n",
    "print(f\"Adding {len(doc_embeddings_int8):,} vectors to INT8 HNSW index...\")\n",
    "hnsw_int8_index.add(doc_embeddings_int8)\n",
    "\n",
    "# Save index\n",
    "faiss.write_index(hnsw_int8_index, hnsw_int8_index_path)\n",
    "hnsw_int8_elapsed = time.time() - hnsw_int8_start\n",
    "\n",
    "index_times['BGE-HNSW-int8'] = hnsw_int8_elapsed\n",
    "print(f\"✅ INT8 HNSW index saved ({hnsw_int8_index.ntotal:,} vectors) ({hnsw_int8_elapsed:.2f}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7d62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INT8 Quantization: Flat index with int8 quantization\n",
    "flat_int8_index_path = os.path.join(base_dir, 'flat_int8_index.faiss')\n",
    "\n",
    "print(\"Building INT8 Flat index (brute-force with quantization)...\")\n",
    "flat_int8_start = time.time()\n",
    "\n",
    "# Create flat index with int8 quantization\n",
    "flat_int8_index = faiss.IndexFlatIP(dimension)\n",
    "flat_int8_index.add(doc_embeddings_int8)\n",
    "\n",
    "# Save index\n",
    "faiss.write_index(flat_int8_index, flat_int8_index_path)\n",
    "flat_int8_elapsed = time.time() - flat_int8_start\n",
    "\n",
    "index_times['BGE-Flat-int8'] = flat_int8_elapsed\n",
    "print(f\"✅ INT8 Flat index saved ({flat_int8_index.ntotal:,} vectors) ({flat_int8_elapsed:.2f}s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92266d2",
   "metadata": {},
   "source": [
    "## 6. Initialize Searchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de01564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 searcher\n",
    "bm25_searcher = LuceneSearcher(bm25_index_dir)\n",
    "bm25_searcher.set_bm25(k1=0.9, b=0.4)\n",
    "\n",
    "# SPLADE searcher (built-in SPLADE query encoding)\n",
    "from pyserini.search.lucene import LuceneImpactSearcher\n",
    "\n",
    "# Initialize with encoder string - searcher will load and use the model internally\n",
    "splade_searcher = LuceneImpactSearcher(\n",
    "    splade_index_dir,\n",
    "    'naver/splade-cocondenser-ensembledistil',  # Model name as string\n",
    "    encoder_type='pytorch',  # Use PyTorch model\n",
    "    #device='cuda'\n",
    ")\n",
    "\n",
    "# Load FAISS indexes for dense retrieval\n",
    "import faiss\n",
    "hnsw_index_path = os.path.join(base_dir, 'hnsw_index.faiss')\n",
    "flat_index_path = os.path.join(base_dir, 'flat_index.faiss')\n",
    "hnsw_int8_index_path = os.path.join(base_dir, 'hnsw_int8_index.faiss')\n",
    "flat_int8_index_path = os.path.join(base_dir, 'flat_int8_index.faiss')\n",
    "\n",
    "hnsw_index = faiss.read_index(hnsw_index_path)\n",
    "flat_index = faiss.read_index(flat_index_path)\n",
    "hnsw_int8_index = faiss.read_index(hnsw_int8_index_path)\n",
    "flat_int8_index = faiss.read_index(flat_int8_index_path)\n",
    "\n",
    "print(f\"✅ All searchers initialized\")\n",
    "print(f\"   HNSW index: {hnsw_index.ntotal:,} vectors\")\n",
    "print(f\"   HNSW-int8 index: {hnsw_int8_index.ntotal:,} vectors\")\n",
    "print(f\"   Flat index: {flat_index.ntotal:,} vectors\")\n",
    "print(f\"   Flat-int8 index: {flat_int8_index.ntotal:,} vectors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebce6ead",
   "metadata": {},
   "source": [
    "## 7. Search Functions\n",
    "\n",
    "Implement search with QPS measurement (16 threads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id_to_idx = {did: i for i, did in enumerate(doc_ids)}\n",
    "\n",
    "def search_bm25(searcher, query_texts, k=1000):\n",
    "    \"\"\"BM25 search\"\"\"\n",
    "    all_indices = []\n",
    "    all_scores = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for q in tqdm(query_texts, desc=\"BM25 search\"):\n",
    "        hits = searcher.search(q, k)\n",
    "        docids = [h.docid for h in hits]\n",
    "        scores = [h.score for h in hits]\n",
    "        all_indices.append([doc_id_to_idx[d] for d in docids])\n",
    "        all_scores.append(scores)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    qps = len(query_texts) / elapsed\n",
    "    \n",
    "    return {\n",
    "        'name': 'BM25',\n",
    "        'indices': np.array(all_indices, dtype=object),\n",
    "        'scores': np.array(all_scores, dtype=object),\n",
    "        'qps': qps\n",
    "    }\n",
    "\n",
    "def search_splade(searcher, query_texts, k=1000):\n",
    "    \"\"\"SPLADE++ ED search\"\"\"\n",
    "    all_indices = []\n",
    "    all_scores = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for q in tqdm(query_texts, desc=\"SPLADE++ ED search\"):\n",
    "        hits = searcher.search(q, k)\n",
    "        docids = [h.docid for h in hits]\n",
    "        scores = [h.score for h in hits]\n",
    "        all_indices.append([doc_id_to_idx[d] for d in docids])\n",
    "        all_scores.append(scores)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    qps = len(query_texts) / elapsed\n",
    "    \n",
    "    return {\n",
    "        'name': 'SPLADE++ ED',\n",
    "        'indices': np.array(all_indices, dtype=object),\n",
    "        'scores': np.array(all_scores, dtype=object),\n",
    "        'qps': qps\n",
    "    }\n",
    "\n",
    "def search_dense(faiss_index, query_embeddings, name, k=1000):\n",
    "    \"\"\"Dense retrieval with FAISS (HNSW or Flat)\"\"\"\n",
    "    all_indices = []\n",
    "    all_scores = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for emb in tqdm(query_embeddings, desc=f\"{name} search\"):\n",
    "        # FAISS search returns (distances, indices)\n",
    "        scores, indices = faiss_index.search(emb.reshape(1, -1), k)\n",
    "        all_indices.append(indices[0].tolist())\n",
    "        all_scores.append(scores[0].tolist())\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    qps = len(query_embeddings) / elapsed\n",
    "    \n",
    "    return {\n",
    "        'name': name,\n",
    "        'indices': np.array(all_indices, dtype=object),\n",
    "        'scores': np.array(all_scores, dtype=object),\n",
    "        'qps': qps\n",
    "    }\n",
    "\n",
    "print(\"✅ Search functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd984c41",
   "metadata": {},
   "source": [
    "## 8. Run All Searches\n",
    "\n",
    "Retrieve 1000 hits per query using 16 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all searches\n",
    "results_bm25 = search_bm25(bm25_searcher, query_texts, k=k_retrieve)\n",
    "results_splade = search_splade(splade_searcher, query_texts, k=k_retrieve)\n",
    "results_hnsw = search_dense(hnsw_index, query_embeddings, 'BGE-HNSW', k=k_retrieve)\n",
    "results_flat = search_dense(flat_index, query_embeddings, 'BGE-Flat', k=k_retrieve)\n",
    "\n",
    "# INT8 quantized searches\n",
    "query_embeddings_int8 = np.clip(query_embeddings * 127, -128, 127).astype(np.int8).astype(np.float32) / 127\n",
    "results_hnsw_int8 = search_dense(hnsw_int8_index, query_embeddings_int8, 'BGE-HNSW-int8', k=k_retrieve)\n",
    "results_flat_int8 = search_dense(flat_int8_index, query_embeddings_int8, 'BGE-Flat-int8', k=k_retrieve)\n",
    "\n",
    "print(\"\\n✅ All searches complete\")\n",
    "print(f\"   BM25: {results_bm25['qps']:.2f} QPS\")\n",
    "print(f\"   SPLADE++ ED: {results_splade['qps']:.2f} QPS\")\n",
    "print(f\"   BGE-HNSW: {results_hnsw['qps']:.2f} QPS\")\n",
    "print(f\"   BGE-HNSW-int8: {results_hnsw_int8['qps']:.2f} QPS\")\n",
    "print(f\"   BGE-Flat: {results_flat['qps']:.2f} QPS\")\n",
    "print(f\"   BGE-Flat-int8: {results_flat_int8['qps']:.2f} QPS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50278285",
   "metadata": {},
   "source": [
    "## 9. Evaluation at nDCG@10\n",
    "\n",
    "Evaluate retrieval quality using nDCG@10 as per BEIR guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a719140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_at_k(retrieved_indices, qrels, query_ids, doc_ids, k=10):\n",
    "    \"\"\"Calculate Recall@k following BEIR guidelines\"\"\"\n",
    "    recalls = []\n",
    "    \n",
    "    for i, qid in enumerate(query_ids):\n",
    "        if qid not in qrels:\n",
    "            continue\n",
    "        \n",
    "        relevant_docs = set(qrels[qid].keys())\n",
    "        retrieved_docs = set([doc_ids[idx] for idx in retrieved_indices[i][:k] if idx >= 0])\n",
    "        \n",
    "        if len(relevant_docs) > 0:\n",
    "            recalls.append(len(relevant_docs & retrieved_docs) / len(relevant_docs))\n",
    "    \n",
    "    return np.mean(recalls) if recalls else 0.0\n",
    "\n",
    "def calculate_ndcg_at_k(retrieved_indices, qrels, query_ids, doc_ids, k=10):\n",
    "    \"\"\"Calculate nDCG@k following BEIR guidelines\"\"\"\n",
    "    ndcgs = []\n",
    "    \n",
    "    for i, qid in enumerate(query_ids):\n",
    "        if qid not in qrels:\n",
    "            continue\n",
    "        \n",
    "        relevant_docs = qrels[qid]\n",
    "        retrieved_docs = [doc_ids[idx] for idx in retrieved_indices[i][:k] if idx >= 0]\n",
    "        \n",
    "        # Calculate DCG\n",
    "        dcg = 0\n",
    "        for rank, doc_id in enumerate(retrieved_docs, 1):\n",
    "            rel = relevant_docs.get(doc_id, 0)\n",
    "            dcg += (2 ** rel - 1) / np.log2(rank + 1)\n",
    "        \n",
    "        # Calculate IDCG\n",
    "        ideal = sorted(relevant_docs.values(), reverse=True)[:k]\n",
    "        idcg = sum((2 ** r - 1) / np.log2(rank + 2) for rank, r in enumerate(ideal))\n",
    "        \n",
    "        ndcgs.append(dcg / idcg if idcg > 0 else 0)\n",
    "    \n",
    "    return np.mean(ndcgs) if ndcgs else 0.0\n",
    "\n",
    "# Evaluate all methods with both metrics\n",
    "for results in [results_bm25, results_splade, results_hnsw, results_flat, results_hnsw_int8, results_flat_int8]:\n",
    "    results['recall@10'] = calculate_recall_at_k(\n",
    "        results['indices'], qrels, query_ids, doc_ids, k=k_eval\n",
    "    )\n",
    "    results['ndcg@10'] = calculate_ndcg_at_k(\n",
    "        results['indices'], qrels, query_ids, doc_ids, k=k_eval\n",
    "    )\n",
    "\n",
    "print(\"✅ Evaluation complete (Recall@10 and nDCG@10 for all methods)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fadaacf",
   "metadata": {},
   "source": [
    "## 10. Results Summary\n",
    "\n",
    "Display results in a table matching the paper format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1015379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe matching paper table format\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'Method': 'BM25',\n",
    "        'Type': 'Sparse (Baseline)',\n",
    "        'Recall@10': results_bm25['recall@10'],\n",
    "        'nDCG@10': results_bm25['ndcg@10'],\n",
    "        'QPS': results_bm25['qps'],\n",
    "    },\n",
    "    {\n",
    "        'Method': 'SPLADE++ ED',\n",
    "        'Type': 'Sparse (Learned)',\n",
    "        'Recall@10': results_splade['recall@10'],\n",
    "        'nDCG@10': results_splade['ndcg@10'],\n",
    "        'QPS': results_splade['qps'],\n",
    "    },\n",
    "    {\n",
    "        'Method': 'BGE-HNSW',\n",
    "        'Type': 'Dense (HNSW)',\n",
    "        'Recall@10': results_hnsw['recall@10'],\n",
    "        'nDCG@10': results_hnsw['ndcg@10'],\n",
    "        'QPS': results_hnsw['qps'],\n",
    "    },\n",
    "    {\n",
    "        'Method': 'BGE-Flat',\n",
    "        'Type': 'Dense (Flat)',\n",
    "        'Recall@10': results_flat['recall@10'],\n",
    "        'nDCG@10': results_flat['ndcg@10'],\n",
    "        'QPS': results_flat['qps'],\n",
    "    },\n",
    "])\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"RESULTS: {dataset_name.upper()}\")\n",
    "print(f\"{'='*90}\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"{'='*90}\")\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Name: {dataset_name}\")\n",
    "print(f\"  Documents (|C|): {len(corpus):,}\")\n",
    "print(f\"  Queries (|Q|): {len(queries):,}\")\n",
    "print(f\"  Relevance judgments: {len(qrels):,}\")\n",
    "print(f\"\\nIndexing Parameters:\")\n",
    "print(f\"  HNSW: M={M}, efC={ef_construction}, efSearch={ef_search}\")\n",
    "print(f\"  Threads: {threads}\")\n",
    "print(f\"\\nRetrieval & Evaluation:\")\n",
    "print(f\"  Retrieved: k={k_retrieve}\")\n",
    "print(f\"  Evaluated: Recall@{k_eval}, nDCG@{k_eval}\")\n",
    "print(f\"  QPS measured with {threads} threads\")\n",
    "print(f\"{'='*90}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2488e9a9",
   "metadata": {},
   "source": [
    "## 10a. Index Time Summary\n",
    "\n",
    "Display the time taken to build each index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index time dataframe\n",
    "index_time_df = pd.DataFrame([\n",
    "    {\n",
    "        'Method': 'BM25',\n",
    "        'Type': 'Sparse (Baseline)',\n",
    "        'Index Time (s)': index_times.get('BM25', 0),\n",
    "    },\n",
    "    {\n",
    "        'Method': 'SPLADE++ ED',\n",
    "        'Type': 'Sparse (Learned)',\n",
    "        'Index Time (s)': index_times.get('SPLADE++ ED', 0),\n",
    "    },\n",
    "    {\n",
    "        'Method': 'BGE-HNSW',\n",
    "        'Type': 'Dense (HNSW)',\n",
    "        'Index Time (s)': index_times.get('BGE-HNSW', 0),\n",
    "    },\n",
    "    {\n",
    "        'Method': 'BGE-Flat',\n",
    "        'Type': 'Dense (Flat)',\n",
    "        'Index Time (s)': index_times.get('BGE-Flat', 0),\n",
    "    },\n",
    "])\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"INDEX TIME: {dataset_name.upper()}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(index_time_df.to_string(index=False))\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total indexing time: {index_time_df['Index Time (s)'].sum():.2f}s\")\n",
    "print(f\"{'='*80}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68eede",
   "metadata": {},
   "source": [
    "## 10b. Table 3: INT8 Quantization - Indexing Time\n",
    "\n",
    "Compare indexing time between full precision and int8 quantized dense indexes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d12f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3: INT8 Quantization - Indexing Time\n",
    "table3_df = pd.DataFrame([\n",
    "    {\n",
    "        'Method': 'BGE-HNSW',\n",
    "        'Quantization': 'FP32',\n",
    "        'Index Time (s)': index_times.get('BGE-HNSW', 0),\n",
    "    },\n",
    "    {\n",
    "        'Method': 'BGE-HNSW',\n",
    "        'Quantization': 'int8',\n",
    "        'Index Time (s)': index_times.get('BGE-HNSW-int8', 0),\n",
    "    },\n",
    "    {\n",
    "        'Method': 'BGE-Flat',\n",
    "        'Quantization': 'FP32',\n",
    "        'Index Time (s)': index_times.get('BGE-Flat', 0),\n",
    "    },\n",
    "    {\n",
    "        'Method': 'BGE-Flat',\n",
    "        'Quantization': 'int8',\n",
    "        'Index Time (s)': index_times.get('BGE-Flat-int8', 0),\n",
    "    },\n",
    "])\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"TABLE 3: INT8 QUANTIZATION - INDEXING TIME: {dataset_name.upper()}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(table3_df.to_string(index=False))\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Calculate speedup\n",
    "fp32_hnsw_time = index_times.get('BGE-HNSW', 1)\n",
    "int8_hnsw_time = index_times.get('BGE-HNSW-int8', 1)\n",
    "hnsw_speedup = fp32_hnsw_time / int8_hnsw_time if int8_hnsw_time > 0 else 1.0\n",
    "\n",
    "fp32_flat_time = index_times.get('BGE-Flat', 1)\n",
    "int8_flat_time = index_times.get('BGE-Flat-int8', 1)\n",
    "flat_speedup = fp32_flat_time / int8_flat_time if int8_flat_time > 0 else 1.0\n",
    "\n",
    "print(f\"Indexing Speedup (FP32 vs int8):\")\n",
    "print(f\"  BGE-HNSW: {hnsw_speedup:.2f}x\")\n",
    "print(f\"  BGE-Flat: {flat_speedup:.2f}x\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae06005",
   "metadata": {},
   "source": [
    "## 10c. Table 4: INT8 Quantization - Query Performance and Quality\n",
    "\n",
    "Compare query performance (QPS) and retrieval quality (nDCG@10) between full precision and int8 quantized dense indexes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad2301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 4: INT8 Quantization - Query Performance and Quality\n",
    "table4_df = pd.DataFrame([\n",
    "    {\n",
    "        'Method': 'BGE-HNSW',\n",
    "        'Quantization': 'FP32',\n",
    "        'QPS': results_hnsw['qps'],\n",
    "        'nDCG@10': results_hnsw['ndcg@10'],\n",
    "        'Recall@10': results_hnsw['recall@10'],\n",
    "    },\n",
    "    {\n",
    "        'Method': 'BGE-HNSW',\n",
    "        'Quantization': 'int8',\n",
    "        'QPS': results_hnsw_int8['qps'],\n",
    "        'nDCG@10': results_hnsw_int8['ndcg@10'],\n",
    "        'Recall@10': results_hnsw_int8['recall@10'],\n",
    "    },\n",
    "    {\n",
    "        'Method': 'BGE-Flat',\n",
    "        'Quantization': 'FP32',\n",
    "        'QPS': results_flat['qps'],\n",
    "        'nDCG@10': results_flat['ndcg@10'],\n",
    "        'Recall@10': results_flat['recall@10'],\n",
    "    },\n",
    "    {\n",
    "        'Method': 'BGE-Flat',\n",
    "        'Quantization': 'int8',\n",
    "        'QPS': results_flat_int8['qps'],\n",
    "        'nDCG@10': results_flat_int8['ndcg@10'],\n",
    "        'Recall@10': results_flat_int8['recall@10'],\n",
    "    },\n",
    "])\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"TABLE 4: INT8 QUANTIZATION - QUERY PERFORMANCE & QUALITY: {dataset_name.upper()}\")\n",
    "print(f\"{'='*100}\")\n",
    "print(table4_df.to_string(index=False))\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "# Calculate query speedup and quality retention\n",
    "fp32_hnsw_qps = results_hnsw['qps']\n",
    "int8_hnsw_qps = results_hnsw_int8['qps']\n",
    "hnsw_qps_speedup = int8_hnsw_qps / fp32_hnsw_qps if fp32_hnsw_qps > 0 else 1.0\n",
    "hnsw_ndcg_retention = (results_hnsw_int8['ndcg@10'] / results_hnsw['ndcg@10'] * 100) if results_hnsw['ndcg@10'] > 0 else 100\n",
    "\n",
    "fp32_flat_qps = results_flat['qps']\n",
    "int8_flat_qps = results_flat_int8['qps']\n",
    "flat_qps_speedup = int8_flat_qps / fp32_flat_qps if fp32_flat_qps > 0 else 1.0\n",
    "flat_ndcg_retention = (results_flat_int8['ndcg@10'] / results_flat['ndcg@10'] * 100) if results_flat['ndcg@10'] > 0 else 100\n",
    "\n",
    "print(f\"Query Performance Speedup (int8 vs FP32):\")\n",
    "print(f\"  BGE-HNSW: {hnsw_qps_speedup:.2f}x (nDCG@10 retention: {hnsw_ndcg_retention:.1f}%)\")\n",
    "print(f\"  BGE-Flat: {flat_qps_speedup:.2f}x (nDCG@10 retention: {flat_ndcg_retention:.1f}%)\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab357754",
   "metadata": {},
   "source": [
    "## 11. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b65ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations matching paper analysis\n",
    "output_dir = f'results_{dataset_name}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "colors = {'Sparse (Baseline)': 'orange', 'Sparse (Learned)': 'red', \n",
    "          'Dense (HNSW)': 'steelblue', 'Dense (Flat)': 'lightblue'}\n",
    "\n",
    "# Plot 1: Speed (QPS) vs Quality (nDCG@10)\n",
    "for _, row in results_df.iterrows():\n",
    "    ax1.scatter(row['QPS'], row['nDCG@10'], \n",
    "              s=200, alpha=0.7, color=colors[row['Type']], \n",
    "              edgecolors='black', linewidth=1.5)\n",
    "    ax1.annotate(row['Method'], \n",
    "               (row['QPS'], row['nDCG@10']), \n",
    "               xytext=(8, 8), textcoords='offset points', \n",
    "               fontsize=10, fontweight='bold')\n",
    "\n",
    "ax1.set_xlabel('QPS (queries per second, 16 threads)', fontsize=11)\n",
    "ax1.set_ylabel('nDCG@10', fontsize=11)\n",
    "ax1.set_title(f'Speed vs Quality (nDCG@10) — {dataset_name}', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Speed (QPS) vs Quality (Recall@10)\n",
    "for _, row in results_df.iterrows():\n",
    "    ax2.scatter(row['QPS'], row['Recall@10'], \n",
    "              s=200, alpha=0.7, color=colors[row['Type']], \n",
    "              edgecolors='black', linewidth=1.5)\n",
    "    ax2.annotate(row['Method'], \n",
    "               (row['QPS'], row['Recall@10']), \n",
    "               xytext=(8, 8), textcoords='offset points', \n",
    "               fontsize=10, fontweight='bold')\n",
    "\n",
    "ax2.set_xlabel('QPS (queries per second, 16 threads)', fontsize=11)\n",
    "ax2.set_ylabel('Recall@10', fontsize=11)\n",
    "ax2.set_title(f'Speed vs Quality (Recall@10) — {dataset_name}', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/speed_vs_quality.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Bar chart comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Quality metrics\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, results_df['Recall@10'], width, label='Recall@10', alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, results_df['nDCG@10'], width, label='nDCG@10', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Method', fontsize=11)\n",
    "ax1.set_ylabel('Score', fontsize=11)\n",
    "ax1.set_title(f'Quality Metrics Comparison — {dataset_name}', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(results_df['Method'], rotation=15, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# QPS comparison\n",
    "bars = ax2.bar(results_df['Method'], results_df['QPS'], alpha=0.8, \n",
    "               color=[colors[t] for t in results_df['Type']], edgecolor='black')\n",
    "ax2.set_xlabel('Method', fontsize=11)\n",
    "ax2.set_ylabel('QPS (16 threads)', fontsize=11)\n",
    "ax2.set_title(f'Query Performance — {dataset_name}', fontsize=12, fontweight='bold')\n",
    "ax2.set_xticklabels(results_df['Method'], rotation=15, ha='right')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/metrics_comparison.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Visualizations complete and saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d8ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INT8 Quantization Comparison Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Indexing Time Comparison\n",
    "ax = axes[0, 0]\n",
    "methods = ['HNSW', 'Flat']\n",
    "fp32_times = [index_times.get('BGE-HNSW', 0), index_times.get('BGE-Flat', 0)]\n",
    "int8_times = [index_times.get('BGE-HNSW-int8', 0), index_times.get('BGE-Flat-int8', 0)]\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, fp32_times, width, label='FP32', alpha=0.8, color='steelblue')\n",
    "ax.bar(x + width/2, int8_times, width, label='int8', alpha=0.8, color='coral')\n",
    "ax.set_xlabel('Index Type', fontsize=11)\n",
    "ax.set_ylabel('Indexing Time (s)', fontsize=11)\n",
    "ax.set_title(f'Indexing Time: FP32 vs int8 — {dataset_name}', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 2: Query Performance (QPS) Comparison\n",
    "ax = axes[0, 1]\n",
    "fp32_qps = [results_hnsw['qps'], results_flat['qps']]\n",
    "int8_qps = [results_hnsw_int8['qps'], results_flat_int8['qps']]\n",
    "\n",
    "ax.bar(x - width/2, fp32_qps, width, label='FP32', alpha=0.8, color='steelblue')\n",
    "ax.bar(x + width/2, int8_qps, width, label='int8', alpha=0.8, color='coral')\n",
    "ax.set_xlabel('Index Type', fontsize=11)\n",
    "ax.set_ylabel('QPS (16 threads)', fontsize=11)\n",
    "ax.set_title(f'Query Performance: FP32 vs int8 — {dataset_name}', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: nDCG@10 Comparison\n",
    "ax = axes[1, 0]\n",
    "fp32_ndcg = [results_hnsw['ndcg@10'], results_flat['ndcg@10']]\n",
    "int8_ndcg = [results_hnsw_int8['ndcg@10'], results_flat_int8['ndcg@10']]\n",
    "\n",
    "ax.bar(x - width/2, fp32_ndcg, width, label='FP32', alpha=0.8, color='steelblue')\n",
    "ax.bar(x + width/2, int8_ndcg, width, label='int8', alpha=0.8, color='coral')\n",
    "ax.set_xlabel('Index Type', fontsize=11)\n",
    "ax.set_ylabel('nDCG@10', fontsize=11)\n",
    "ax.set_title(f'Retrieval Quality (nDCG@10): FP32 vs int8 — {dataset_name}', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Speed-Quality Tradeoff\n",
    "ax = axes[1, 1]\n",
    "colors_int8 = {'FP32': 'steelblue', 'int8': 'coral'}\n",
    "for method, qps, ndcg, quantization in [\n",
    "    ('HNSW-FP32', results_hnsw['qps'], results_hnsw['ndcg@10'], 'FP32'),\n",
    "    ('HNSW-int8', results_hnsw_int8['qps'], results_hnsw_int8['ndcg@10'], 'int8'),\n",
    "    ('Flat-FP32', results_flat['qps'], results_flat['ndcg@10'], 'FP32'),\n",
    "    ('Flat-int8', results_flat_int8['qps'], results_flat_int8['ndcg@10'], 'int8'),\n",
    "]:\n",
    "    ax.scatter(qps, ndcg, s=200, alpha=0.7, color=colors_int8[quantization], \n",
    "              edgecolors='black', linewidth=1.5)\n",
    "    ax.annotate(method, (qps, ndcg), xytext=(8, 8), textcoords='offset points', \n",
    "               fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('QPS (16 threads)', fontsize=11)\n",
    "ax.set_ylabel('nDCG@10', fontsize=11)\n",
    "ax.set_title(f'Speed-Quality Tradeoff: FP32 vs int8 — {dataset_name}', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/int8_quantization_comparison.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ INT8 quantization comparison visualizations saved to {output_dir}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f8d6ff",
   "metadata": {},
   "source": [
    "## 12. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e2ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "output_dir = f'results_{dataset_name}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "results_path = os.path.join(output_dir, f'{dataset_name}_results.csv')\n",
    "results_df.to_csv(results_path, index=False)\n",
    "\n",
    "# Save index times to CSV\n",
    "index_time_path = os.path.join(output_dir, f'{dataset_name}_index_times.csv')\n",
    "index_time_df.to_csv(index_time_path, index=False)\n",
    "\n",
    "# Save Table 3 (INT8 Indexing Time)\n",
    "table3_path = os.path.join(output_dir, f'{dataset_name}_table3_int8_indexing.csv')\n",
    "table3_df.to_csv(table3_path, index=False)\n",
    "\n",
    "# Save Table 4 (INT8 Query Performance & Quality)\n",
    "table4_path = os.path.join(output_dir, f'{dataset_name}_table4_int8_performance.csv')\n",
    "table4_df.to_csv(table4_path, index=False)\n",
    "\n",
    "# Save detailed results with metadata\n",
    "metadata = {\n",
    "    'dataset': dataset_name,\n",
    "    'num_documents': len(corpus),\n",
    "    'num_queries': len(queries),\n",
    "    'num_qrels': len(qrels),\n",
    "    'hnsw_M': M,\n",
    "    'hnsw_efC': ef_construction,\n",
    "    'hnsw_efSearch': ef_search,\n",
    "    'threads': threads,\n",
    "    'k_retrieve': k_retrieve,\n",
    "    'k_eval': k_eval,\n",
    "    'index_times': index_times,\n",
    "    'total_indexing_time': float(index_time_df['Index Time (s)'].sum()),\n",
    "    'int8_quantization': {\n",
    "        'method': 'simple_linear_quantization',\n",
    "        'scale': 127,\n",
    "        'range': '[-128, 127]',\n",
    "    },\n",
    "    'speedup': {\n",
    "        'hnsw_indexing': float(fp32_hnsw_time / int8_hnsw_time) if int8_hnsw_time > 0 else None,\n",
    "        'flat_indexing': float(fp32_flat_time / int8_flat_time) if int8_flat_time > 0 else None,\n",
    "        'hnsw_query': float(hnsw_qps_speedup),\n",
    "        'flat_query': float(flat_qps_speedup),\n",
    "    },\n",
    "    'quality_retention': {\n",
    "        'hnsw_ndcg': float(hnsw_ndcg_retention),\n",
    "        'flat_ndcg': float(flat_ndcg_retention),\n",
    "    },\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(output_dir, f'{dataset_name}_metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"✅ Results saved:\")\n",
    "print(f\"   - {results_path}\")\n",
    "print(f\"   - {index_time_path}\")\n",
    "print(f\"   - {table3_path} (Table 3: INT8 Indexing Time)\")\n",
    "print(f\"   - {table4_path} (Table 4: INT8 Query Performance)\")\n",
    "print(f\"   - {metadata_path}\")\n",
    "print(f\"   - {output_dir}/speed_vs_quality.pdf\")\n",
    "print(f\"   - {output_dir}/metrics_comparison.pdf\")\n",
    "print(f\"   - {output_dir}/int8_quantization_comparison.pdf\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SUMMARY - PAPER TABLES REPLICATED:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"✅ Table 1: Dense vs Sparse Retrieval Baseline Results\")\n",
    "print(f\"✅ Table 3: INT8 Quantization - Indexing Time Comparison\")\n",
    "print(f\"✅ Table 4: INT8 Quantization - Query Performance & Quality\")\n",
    "print(f\"{'='*80}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012d132",
   "metadata": {},
   "source": [
    "## 13. Download Results to Local Machine\n",
    "\n",
    "Detect environment (Colab/Kaggle/Local) and download all results and visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357aa9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect environment and download/copy results\n",
    "import shutil\n",
    "import platform\n",
    "\n",
    "def detect_environment():\n",
    "    \"\"\"Detect if running on Colab, Kaggle, or Local\"\"\"\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        return 'colab'\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    if os.path.exists('/kaggle/'):\n",
    "        return 'kaggle'\n",
    "    \n",
    "    return 'local'\n",
    "\n",
    "environment = detect_environment()\n",
    "print(f\"Environment detected: {environment.upper()}\")\n",
    "\n",
    "if environment == 'colab':\n",
    "    # Google Colab: Mount Google Drive and copy results\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/gdrive', force_remount=True)\n",
    "        \n",
    "        colab_save_dir = f'/content/gdrive/My Drive/BEIR_Results/{dataset_name}'\n",
    "        os.makedirs(colab_save_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy entire results directory to Google Drive\n",
    "        shutil.copytree(output_dir, os.path.join(colab_save_dir, 'results'), dirs_exist_ok=True)\n",
    "        shutil.copytree(base_dir, os.path.join(colab_save_dir, 'indexes'), dirs_exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n✅ Results saved to Google Drive: {colab_save_dir}\")\n",
    "        print(f\"\\nFiles saved:\")\n",
    "        for root, dirs, files in os.walk(colab_save_dir):\n",
    "            level = root.replace(colab_save_dir, '').count(os.sep)\n",
    "            indent = ' ' * 2 * level\n",
    "            print(f\"{indent}{os.path.basename(root)}/\")\n",
    "            subindent = ' ' * 2 * (level + 1)\n",
    "            for file in files:\n",
    "                print(f\"{subindent}{file}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not mount Google Drive: {e}\")\n",
    "        print(f\"Files remain in: {output_dir}\")\n",
    "\n",
    "elif environment == 'kaggle':\n",
    "    # Kaggle: Save to /kaggle/working/ (synced to outputs)\n",
    "    kaggle_save_dir = f'/kaggle/working/BEIR_Results_{dataset_name}'\n",
    "    os.makedirs(kaggle_save_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy entire results directory\n",
    "    shutil.copytree(output_dir, os.path.join(kaggle_save_dir, 'results'), dirs_exist_ok=True)\n",
    "    shutil.copytree(base_dir, os.path.join(kaggle_save_dir, 'indexes'), dirs_exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n✅ Results saved to Kaggle working directory: {kaggle_save_dir}\")\n",
    "    print(f\"Files will be available in 'Output' section when notebook completes\")\n",
    "    print(f\"\\nFiles saved:\")\n",
    "    for root, dirs, files in os.walk(kaggle_save_dir):\n",
    "        level = root.replace(kaggle_save_dir, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            print(f\"{subindent}{file}\")\n",
    "\n",
    "else:\n",
    "    # Local execution: Files are already saved\n",
    "    print(f\"\\n✅ Results already saved locally to: {output_dir}\")\n",
    "    print(f\"\\nFiles saved:\")\n",
    "    for root, dirs, files in os.walk(output_dir):\n",
    "        level = root.replace(output_dir, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_size = os.path.getsize(file_path) / 1024  # Size in KB\n",
    "            print(f\"{subindent}{file} ({file_size:.1f} KB)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"RESULTS SUMMARY:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Index directory: {base_dir}\")\n",
    "print(f\"\\nGenerated files:\")\n",
    "print(f\"  📊 {dataset_name}_results.csv - Main results (Dense/Sparse comparison)\")\n",
    "print(f\"  ⏱️  {dataset_name}_index_times.csv - Index construction times\")\n",
    "print(f\"  🔢 {dataset_name}_table3_int8_indexing.csv - Table 3 (INT8 indexing)\")\n",
    "print(f\"  📈 {dataset_name}_table4_int8_performance.csv - Table 4 (INT8 performance)\")\n",
    "print(f\"  📝 {dataset_name}_metadata.json - Complete metadata & speedup metrics\")\n",
    "print(f\"  📉 speed_vs_quality.pdf - Quality vs Speed scatter plots\")\n",
    "print(f\"  📊 metrics_comparison.pdf - Bar chart comparisons\")\n",
    "print(f\"  🔄 int8_quantization_comparison.pdf - INT8 quantization analysis\")\n",
    "print(f\"\\nIndexes saved:\")\n",
    "print(f\"  • BM25 Lucene index\")\n",
    "print(f\"  • SPLADE++ ED impact index\")\n",
    "print(f\"  • BGE-HNSW (FP32 and int8)\")\n",
    "print(f\"  • BGE-Flat (FP32 and int8)\")\n",
    "print(f\"{'='*80}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
